{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9754c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this file I'll clean the different files. \n",
    "#Then I'll evaluate the potential relations among the records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "498fc232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import import_ipynb\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Wenders level 4K graphics.\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#This make the graph possible\n",
    "%matplotlib inline\n",
    "\n",
    "#Functions\n",
    "from src.funk import Funk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57a38ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##A general overview has already been done on the raw csv files.\n",
    "#I'll start by dropping update columns and language related data since there are only english spoken content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbcc94bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loading data\n",
    "\n",
    "actor = pd.read_csv('data/actor.csv', encoding= \"ISO-8859-1\")\n",
    "category = pd.read_csv('data/category.csv', encoding= \"ISO-8859-1\")\n",
    "film = pd.read_csv('data/film.csv', encoding= \"ISO-8859-1\")\n",
    "inventory = pd.read_csv('data/inventory.csv', encoding= \"ISO-8859-1\")\n",
    "old_HDD = pd.read_csv('data/old_HDD.csv', encoding= \"ISO-8859-1\")\n",
    "rental = pd.read_csv('data/rental.csv', encoding= \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ce21cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "del actor['last_update']\n",
    "del category['last_update']\n",
    "del inventory['last_update']\n",
    "del rental['last_update']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea8c48bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "film.drop(['language_id', 'original_language_id', 'last_update'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0848c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframes were checked for null values, they seem clean.\n",
    "#All the info in them seems useful, time to relate it and build a database.\n",
    "#actor.shape 200,3\n",
    "#category.shape 16,2\n",
    "#film.shape 1000,10\n",
    "#inventory.shape 1000,3\n",
    "#old_HDD.shape 1000,5\n",
    "#rental.shape 1000,6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "797d6be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From a quick overview and my assumption I can relate 2 general groups of info:\n",
    "\n",
    "#Given_data, as in actor, category and film. This data is true regardless of the business, and won't change.\n",
    "#Created__data as in inventory, old_HDD and rental. This is business history, and will fluctuate ahead.\n",
    "#Probably as of now, film and inventory are matching, since both have 1K records. \n",
    "#The zip among those two could very well be the bridge for all data.\n",
    "\n",
    "#Drawing time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bbe60ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contrary of the initial thought, film cannot relate category and actor.\n",
    "\n",
    "#inventory shows there are two stores, each with half the movies.\n",
    "#inventory also shows there are 1000 dvds, but only 207 unique titles.\n",
    "\n",
    "#rental shows that the staff counts 2 entities, each renting more or less half the volume.\n",
    "#rental shows there are 485 customers, they have rented in a range 8 to 1, 75% of them have rented less than 3.\n",
    "\n",
    "#oldHDD will just be merged with film and that will be the database core."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9331ae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor['name'] = actor['first_name'] +' '+ actor['last_name']\n",
    "old_HDD['name'] = old_HDD['first_name'] +' '+ old_HDD['last_name']\n",
    "actor.drop(['first_name', 'last_name'], axis=1, inplace=True)\n",
    "old_HDD.drop(['first_name', 'last_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b4bd0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#film has 1000 unique id and title\n",
    "#old_HDD has 614 unique title, 39 unique actor name\n",
    "#from old_HDD, film is missing the category.\n",
    "#old_HDD will be used to create the new table with film_id and actor_id\n",
    "\n",
    "film2 = pd.merge(film, old_HDD, how=\"left\", on=[\"title\"])\n",
    "film2.drop(['release_year_y', 'name'], axis=1, inplace=True)\n",
    "film2 = film2.drop_duplicates()\n",
    "old_HDD.drop(['release_year', 'category_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "725aa0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tit_id = film[['film_id', 'title']]\n",
    "act_id = actor[['actor_id', 'name']]\n",
    "\n",
    "merg1 = pd.merge(old_HDD, tit_id, how=\"left\", on=[\"title\"])\n",
    "merg2 = pd.merge(merg1, act_id, how=\"left\", on=[\"name\"])\n",
    "merg2.drop(['title', 'name'], axis=1, inplace=True)\n",
    "title_actor = merg2.drop_duplicates()\n",
    "\n",
    "#614 unique title achieved, the one with more actors has 6, the less 1\n",
    "#39 unique actors, the one on more titles is on 37, the less on 7\n",
    "#title_actor['film_id'].value_counts()\n",
    "#title_actor['actor_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f16a9f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "cinefilo = rental.customer_id.value_counts()\n",
    "stats = cinefilo.describe()\n",
    "stats['IQR'] = stats['75%'] - stats['25%']\n",
    "#stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5c9adf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 0 to 1385\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   film_id           1000 non-null   int64  \n",
      " 1   title             1000 non-null   object \n",
      " 2   description       1000 non-null   object \n",
      " 3   release_year_x    1000 non-null   int64  \n",
      " 4   rental_duration   1000 non-null   int64  \n",
      " 5   rental_rate       1000 non-null   float64\n",
      " 6   length            1000 non-null   int64  \n",
      " 7   replacement_cost  1000 non-null   float64\n",
      " 8   rating            1000 non-null   object \n",
      " 9   special_features  1000 non-null   object \n",
      " 10  category_id       614 non-null    float64\n",
      "dtypes: float64(3), int64(4), object(4)\n",
      "memory usage: 93.8+ KB\n"
     ]
    }
   ],
   "source": [
    "film2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5da3182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning seams ready, the next file will construct the database.\n",
    "#Exporting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdaea415",
   "metadata": {},
   "outputs": [],
   "source": [
    "category.to_csv('data/category_clean.csv', index=False)\n",
    "actor.to_csv('data/actor_clean.csv', index=False)\n",
    "rental.to_csv('data/rental_clean.csv', index=False)\n",
    "inventory.to_csv('data/inventory_clean.csv', index=False)\n",
    "film2.to_csv('data/film_clean.csv', index=False)\n",
    "title_actor.to_csv('data/title_actor.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
